{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from importlib import reload\n",
    "import loss\n",
    "import data_generator\n",
    "import model\n",
    "import train\n",
    "import visualize\n",
    "reload(loss)\n",
    "reload(visualize)\n",
    "reload(model)\n",
    "reload(data_generator)\n",
    "reload(train)\n",
    "\n",
    "from data_generator import make_dataloaders\n",
    "from model import MainModel\n",
    "from train import train_model, load_model, build_backbone_unet, pretrain_generator\n",
    "from background_detection import load_processed_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 5\n",
    "EPOCHS = 50\n",
    "TRAIN_SET_SIZE = 0.8\n",
    "COLOR_SPACE = 'YCbCr' # Lab or HSL or YCbCr\n",
    "BACKBONE = 'resnet34' # backbones: resnet18, resnet34, vgg16_bn\n",
    "path = \"./data/part1\"\n",
    "l1loss = \"L1Loss\" # SmoothL1Loss or L1Loss\n",
    "ganloss = \"lsgan\" # vanilla or lsgan\n",
    "\n",
    "model_name = f\"pretrained_noBG_part1_{BACKBONE}_{COLOR_SPACE}_{l1loss}_{ganloss}_FULL\"\n",
    "model_path =  f\"./models/model_{model_name}.pt\"\n",
    "paths1 = load_processed_images('./background_scores/filtered_part1')\n",
    "paths2 = load_processed_images('./background_scores/filtered_part2')\n",
    "paths3 = load_processed_images('./background_scores/filtered_part3')\n",
    "paths = paths1 + paths2 + paths3\n",
    "pretrained_model = f\"{BACKBONE}-unet_noBG_{COLOR_SPACE}_FULL.pt\"\n",
    "np.random.seed(123)\n",
    "total_paths = len(paths) - (len(paths) % BATCH_SIZE)\n",
    "len_train_paths = int(total_paths * TRAIN_SET_SIZE)\n",
    "paths_subset = np.random.choice(paths, total_paths, replace=False) # choosing 1000 images randomly\n",
    "rand_idxs = np.random.permutation(total_paths)\n",
    "train_idxs = rand_idxs[:len_train_paths] # choosing the first 80% as training set\n",
    "val_idxs = rand_idxs[len_train_paths:] # choosing last 20% as validation set\n",
    "train_paths = paths_subset[train_idxs]\n",
    "val_paths = paths_subset[val_idxs]\n",
    "print(len(train_paths), len(val_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axes = plt.subplots(4, 4, figsize=(10, 10))\n",
    "for ax, img_path in zip(axes.flatten(), train_paths):\n",
    "    ax.imshow(Image.open(img_path))\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = make_dataloaders(batch_size=BATCH_SIZE, paths=train_paths, split='train', color_space=COLOR_SPACE)\n",
    "val_dl = make_dataloaders(batch_size=BATCH_SIZE, paths=val_paths, split='val', color_space=COLOR_SPACE)\n",
    "\n",
    "data = next(iter(train_dl))\n",
    "known_channels, unknown_channels_ = data['known_channel'], data['unknown_channels']\n",
    "print(known_channels.shape, unknown_channels_.shape)\n",
    "print(len(train_dl), len(val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net_G = build_backbone_unet(n_input=1, n_output=2, size=256, backbone_name=BACKBONE)\n",
    "# opt = torch.optim.Adam(net_G.parameters(), lr=1e-4)\n",
    "# criterion = torch.nn.L1Loss()        \n",
    "# pretrain_generator(net_G, train_dl, opt, criterion, 20, device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net_G.state_dict(), pretrained_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_G = build_backbone_unet(n_input=1, n_output=2, size=256, backbone_name=BACKBONE)\n",
    "net_G.load_state_dict(torch.load(pretrained_model, map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = MainModel(net_G=net_G, L1LossType=l1loss, ganloss=ganloss)\n",
    "# _, loss_meter_dict = load_model(model_path, loaded_model) # for model loaded from file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# #  train_model(loaded_model, train_dl, val_dl, COLOR_SPACE, 150, 10, loss_meter_dict=loss_meter_dict, save_path=model_path) # for model loaded from file\n",
    "# train_model(loaded_model, train_dl, val_dl, COLOR_SPACE, EPOCHS, 600, save_path=model_path) # for model trained from the begining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from visualize import visualize\n",
    "\n",
    "loaded_model = MainModel(net_G=net_G, L1LossType=l1loss, ganloss=ganloss)\n",
    "model, loss_meter_dict, train_loss_meter_dict = load_model(model_path, loaded_model) \n",
    "start_idx = 5\n",
    "number_of_sets = 5\n",
    "for i, data in enumerate(iter(val_dl)):\n",
    "    if i >= start_idx:\n",
    "        visualize(loaded_model, data, COLOR_SPACE, save=True, set_num=i-start_idx, model_name=model_name)\n",
    "    if i == start_idx + number_of_sets-1:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
